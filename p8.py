import streamlit as st
import datetime
from langchain.chat_models import ChatOpenAI
from langchain.schema import Document
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chains import RetrievalQA

# --- LangChain ì´ˆê¸°í™” ---
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
embeddings = OpenAIEmbeddings()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "docs" not in st.session_state:
    st.session_state.docs = []

# --- Streamlit UI ---
st.title("ğŸ“… ë‹¬ë ¥ì— ë©”ëª¨í•˜ê¸°")

# ì˜¤ëŠ˜ ë‚ ì§œ
today = datetime.date.today()
date = st.date_input("ë‚ ì§œ ì„ íƒ", today)

# ë©”ëª¨ ì…ë ¥
memo = st.text_area("ë©”ëª¨ ì…ë ¥")
if st.button("ì €ì¥"):
    if memo.strip():
        doc = Document(page_content=memo, metadata={"date": str(date)})
        st.session_state.docs.append(doc)
        st.session_state.vectorstore = FAISS.from_documents(st.session_state.docs, embeddings)
        st.success(f"{date} ë©”ëª¨ ì €ì¥ ì™„ë£Œ!")

# ì „ì²´ ë©”ëª¨ ë³´ê¸°
st.subheader("ğŸ“‚ ì „ì²´ ë©”ëª¨")
if st.session_state.docs:
    for i, d in enumerate(st.session_state.docs):
        col1, col2 = st.columns([8, 1])
        with col1:
            st.markdown(f"**{d.metadata['date']}** : {d.page_content}")
        with col2:
            if st.button("ğŸ—‘ï¸", key=f"delete_{i}"):
                # ì‚­ì œ: í•´ë‹¹ ë¬¸ì„œ ì œê±° í›„ vectorstore ì¬ìƒì„±
                st.session_state.docs.pop(i)
                if st.session_state.docs:
                    st.session_state.vectorstore = FAISS.from_documents(st.session_state.docs, embeddings)
                else:
                    st.session_state.vectorstore = None
                st.rerun()   # âœ… ìµœì‹  Streamlitì—ì„œëŠ” st.experimental_rerun() ëŒ€ì‹  st.rerun() ì‚¬ìš©
else:
    st.info("ì•„ì§ ì €ì¥ëœ ë©”ëª¨ê°€ ì—†ìŠµë‹ˆë‹¤.")

from langchain_core.prompts import PromptTemplate

# AIì—ê²Œ ì§ˆë¬¸
st.subheader("â“ AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°")
question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")
if st.button("ì§ˆë¬¸í•˜ê¸°"):
    if question.strip():
        if not st.session_state.docs:
            st.warning("ë¨¼ì € ë©”ëª¨ë¥¼ ì €ì¥í•´ì£¼ì„¸ìš”.")
        else:
            # ëª¨ë“  ë©”ëª¨ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
            all_memos = "\n".join(
                [f"- {d.metadata['date']}: {d.page_content}" for d in st.session_state.docs]
            )

            # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ì˜ˆì‹œì½”ë“œ(page7.py) ì°¸ê³ í•´ì„œ ì„¤ê³„)
            qa_template = PromptTemplate(
                input_variables=["memos", "question"],
                template=(
                    "ë‹¹ì‹ ì€ ê°œì¸ ë¹„ì„œì…ë‹ˆë‹¤. ì•„ë˜ ë‹¬ë ¥ ë©”ëª¨ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n\n"
                    "ë©”ëª¨ ëª©ë¡:\n{memos}\n\n"
                    "ì§ˆë¬¸: {question}\n\n"
                    "ê·œì¹™:\n"
                    "- ë°˜ë“œì‹œ ë©”ëª¨ ë‚´ìš©ê³¼ ê°œìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.\n"
                    "- ë©”ëª¨ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ë§ê³  'ë©”ëª¨ì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë‹µí•˜ì„¸ìš”.\n"
                    "- í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n\n"
                    "ë‹µë³€:"
                )
            )

            prompt = qa_template.format(memos=all_memos, question=question)

            try:
                answer = llm.predict(prompt)
                st.write(answer)
            except Exception as e:
                st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")