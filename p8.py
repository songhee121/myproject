import streamlit as st
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from streamlit_chat import message
from MyLCH import getOpenAI  # ì‚¬ìš©ìì˜ LLM ë˜í¼

st.markdown("ì±„íŒ…í•˜ê¸°")
st.sidebar.markdown("í•™ìŠµí•œ ë‚´ìš©ì„ ì£¼ì œë¡œ í† ë¡ /í† ì˜í•˜ë©° ì§€ì‹ì„ í™•ì¥í•´ìš”")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”(ì¼ê´€ëœ í‚¤ ì‚¬ìš©) ---
if 'memory' not in st.session_state:
    st.session_state['memory'] = ConversationBufferMemory(return_messages=True)

if 'conv_chain' not in st.session_state:
    # LLM ê°ì²´ëŠ” ì„¸ì…˜ ì•ˆì— ë³´ê´€(ê°™ì€ í”„ë¡œì„¸ìŠ¤ ë‚´ì—ì„œë§Œ ìœ íš¨)
    st.session_state['conv_chain'] = ConversationChain(
        llm=getOpenAI(),
        memory=st.session_state['memory'],
        verbose=False
    )

if 'chat_past' not in st.session_state:
    st.session_state['chat_past'] = ["ì•ˆë…•í•˜ì„¸ìš”!"]  # ì‚¬ìš©ì ë°œí™”(ì´ˆê¸°ê°’ì€ ëŒ€í™” ì‹œì‘ í”„ë¡¬í”„íŠ¸ì™€ ë§ì¶”ê¸° ìœ„í•¨)

if 'chat_generated' not in st.session_state:
    st.session_state['chat_generated'] = ["ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ì£¼ì œë¡œ ì´ì•¼ê¸°ë¥¼ í•´ë³¼ê¹Œìš”?"]  # ë´‡ ì‘ë‹µ

# --- ì´ˆê¸°í™”(ë©”ëª¨ë¦¬ ë¦¬ì…‹) ë²„íŠ¼ ---
if st.sidebar.button("ëŒ€í™” ì´ˆê¸°í™” (ë©”ëª¨ë¦¬ ì‚­ì œ)"):
    st.session_state['memory'] = ConversationBufferMemory(return_messages=True)
    st.session_state['conv_chain'] = ConversationChain(
        llm=getOpenAI(),
        memory=st.session_state['memory'],
        verbose=False
    )
    st.session_state['chat_past'] = ["ì•ˆë…•í•˜ì„¸ìš”!"]
    st.session_state['chat_generated'] = ["ì•ˆë…•í•˜ì„¸ìš”! ì–´ë–¤ ì£¼ì œë¡œ ì´ì•¼ê¸°ë¥¼ í•´ë³¼ê¹Œìš”?"]
    st.success("ëŒ€í™”ì™€ ë©”ëª¨ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

# --- ì±„íŒ… í•¨ìˆ˜(ì„¸ì…˜ ë‚´ ì²´ì¸ ì‚¬ìš©, ë©”ëª¨ë¦¬ì— ìë™ ì €ì¥) ---
def conversational_chat(user_query: str) -> str:
    chain: ConversationChain = st.session_state['conv_chain']
    # chain.predictëŠ” memoryì— ëŒ€í™”ë¥¼ ì €ì¥í•´ì¤ë‹ˆë‹¤.
    try:
        response = chain.predict(input=user_query)
    except Exception as e:
        # LLM í˜¸ì¶œ ì‹¤íŒ¨ì‹œ ì˜ˆì™¸ ì²˜ë¦¬
        response = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    # ì„¸ì…˜ ì±„íŒ… íˆìŠ¤í† ë¦¬ ê°±ì‹ 
    st.session_state['chat_past'].append(user_query)
    st.session_state['chat_generated'].append(response)
    return response

# --- UI: ì…ë ¥ í¼ ---
response_container = st.container()
container = st.container()

with container:
    with st.form(key='Conv_Question', clear_on_submit=True):
        user_input = st.text_input("Query:", placeholder="ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš” ğŸ™‚", key='input')
        submit_button = st.form_submit_button(label='Send')

    if submit_button and user_input:
        with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
            conversational_chat(user_input)

# --- ëŒ€í™” ì¶œë ¥(ì €ì¥ëœ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì‚¬ìš©) ---
if st.session_state['chat_generated']:
    with response_container:
        # chat_pastì™€ chat_generatedì˜ ê¸¸ì´ê°€ ê°™ì€ì§€ ì•ˆì „ ê²€ì‚¬
        n = min(len(st.session_state['chat_past']), len(st.session_state['chat_generated']))
        for i in range(n):
            # ì‚¬ìš©ì ë©”ì‹œì§€
            message(st.session_state['chat_past'][i],
                    is_user=True,
                    key=f"user_{i}",
                    avatar_style="fun-emoji",
                    seed="Nala")
            # ë´‡ ë©”ì‹œì§€
            message(st.session_state['chat_generated'][i],
                    key=f"bot_{i}",
                    avatar_style="bottts",
                    seed="Fluffy")